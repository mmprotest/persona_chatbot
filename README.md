# Persona Chatbot

A fully fledged persona-driven AI companion built with Python and Streamlit. The agent is designed to run against OpenAI-compatible APIs as well as local models served via [Ollama](https://ollama.com/). It maintains a long-term memory store, reflects on each response, and offers a realistic conversational experience.

## Features

- **Persona adherence** â€“ Configure the assistant's name, description, and goals via environment variables.
- **Automatic worldbuilding** â€“ The agent generates a full biography, relationships, signature memories, and sample dialogues on startup.
- **OpenAI & Ollama support** â€“ Swap between providers by setting `LLM_PROVIDER` while keeping API compatibility.
- **Long-term memory** â€“ SQLite-backed vector store remembers past interactions and reflections.
- **Self-reflection loop** â€“ Each response is drafted, reviewed, and refined for authenticity.
- **Editable chat history** â€“ Modify both user and assistant messages directly within the Streamlit UI.
- **Memory browser** â€“ Inspect the most recent stored memories and reflections from the sidebar.

## Getting Started

### Prerequisites

- Python 3.10+
- Recommended dependencies:
  - `streamlit`
  - `openai`
  - `requests`
  - `sentence-transformers`
  - `numpy`

Install dependencies:

```bash
pip install -r requirements.txt
```

> If you prefer manual installation, ensure the packages listed above are available in your environment.

### Configuration

Environment variables control the persona, memory, and model settings. The most common options include:

| Variable | Description | Default |
| --- | --- | --- |
| `LLM_PROVIDER` | `openai` or `ollama` | `openai` |
| `LLM_MODEL` | Model name for the chosen provider | `gpt-4o-mini` |
| `LLM_API_KEY` | API key for OpenAI-compatible endpoints | â€“ |
| `LLM_BASE_URL` | Override the base URL (useful for local gateways) | â€“ |
| `MEMORY_DB_PATH` | Path to the SQLite database | `./data/memory.sqlite` |
| `EMBEDDING_MODEL` | SentenceTransformer model for embeddings | `all-MiniLM-L6-v2` |
| `PERSONA_NAME` | Assistant persona name | `Avery` |
| `PERSONA_DESCRIPTION` | Persona backstory | `A thoughtful AI companion...` |
| `PERSONA_SEED` | Extra hints to steer the autogenerated life story | â€“ |

### Running the App

Launch the Streamlit interface:

```bash
streamlit run streamlit_app.py
```

Interact with the chatbot through the chat input. Each exchange is automatically reflected upon, refined, and stored. Use the sidebar to reset the conversation or review recent memories.

The sidebar reveals the generated persona dossier so you can see the assistant's biography, traits, and daily rhythm at a glance. After each turn you'll also find the agent's self-reflection notes, the retrieved context, and a forward-looking relationship plan.

### Using Ollama

To run with a local Ollama model, ensure the server is running and set the environment variables:

```bash
export LLM_PROVIDER=ollama
export LLM_MODEL=llama3
streamlit run streamlit_app.py
```

### Data Storage

Long-term memories are saved in a SQLite database specified by `MEMORY_DB_PATH`. Each entry includes the role, content, metadata, and embedding for similarity search.

## Development Notes

- Memory embeddings default to `sentence-transformers`. If unavailable, the app falls back to the active LLM provider for embeddings.
- Editing a message updates the associated memory embedding to keep retrieval consistent.
- Reflections are stored separately and surfaced in the sidebar for transparency.
- Every session seeds long-term memory with persona biography, life timeline, relationships, and simulated conversations so the character feels lived-in immediately.

Enjoy exploring rich, persona-driven conversations! ðŸ§ 
